---
layout: post
title: DeepLearning.aiç¬”è®°ï¼ˆä¸€ï¼‰
date: 2018-03-11 10:00:00 +0800
categories: æœºå™¨å­¦ä¹ 
tags: éšç¬”
toc: true
comments: true
mathjax: true
---
ç½‘ä¸Šå…³äº[ç¥ç»ç½‘ç»œå’Œæ·±åº¦å­¦ä¹ ](http://mooc.study.163.com/course/2001281002#/info)çš„ç¬”è®°ã€ä½œä¸šå¾ˆå¤šï¼Œä¹Ÿå¾ˆæœ‰ä»·å€¼ã€‚è¿™ç‰ˆç¬”è®°è¿™æ˜¯é’ˆå¯¹æˆ‘è‡ªå·±å­¦ä¹ è¿‡ç¨‹ä¸­çš„æ„Ÿæ‚Ÿã€é‡ç‚¹åšä¸ªè®°å½•ï¼Œä¾¿äºè‡ªå·±å¿«é€ŸæŸ¥é˜…ã€‚æœ¬æ–‡çš„æ ‡é¢˜å·å’Œè¯¾ç¨‹å·ä¿æŒä¸€è‡´ï¼Œä»¥æ–¹ä¾¿æŸ¥é˜…ã€‚
<!-- more -->

# 2.1 æ ·æœ¬çš„è¡¨ç¤º

é¢˜ç›®çš„ç›®æ ‡æ˜¯åˆ¤æ–­å›¾ç‰‡ä¸­æ˜¯å¦æœ‰çŒ«ï¼Œå‡è®¾ä¸€å¼ å›¾æ˜¯64Ã—64åƒç´ ï¼Œ3é€šé“ï¼Œå³Rã€Gã€Båˆ†åˆ«å¯¹åº”ä¸€ä¸ª64Ã—64çš„çŸ©é˜µï¼š

R = $\left\lgroup \matrix{R_{1\,1} & R_{1\,2} & ... & R_{1\,64} \cr R_{2\,1} & R_{2\,2} & ... & R_{2\,64} \cr ... & ... & ... \cr R_{64\,1} & R_{64\,2} & ... & R_{64\,64} } \right \rgroup$ $\;$ G = $\left\lgroup \matrix{G_{1\,1} & G_{1\,2} & ... & G_{1\,64} \cr G_{2\,1} & G_{2\,2} & ... & G_{2\,64} \cr ... & ... & ... \cr G_{64\,1} & G_{64\,2} & ... & G_{64\,64} } \right \rgroup$ $\;$  B = $\left\lgroup \matrix{B_{1\,1} & B_{1\,2} & ... & B_{1\,64} \cr B_{2\,1} & B_{2\,2} & ... & B_{2\,64} \cr ... & ... & ... \cr B_{64\,1} & B_{64\,2} & ... & B_{64\,64} } \right \rgroup$ 

éœ€è¦å°†è¯¥æ ·æœ¬è½¬æ¢æˆä¸€ä¸ªä¸€ç»´æ•°ç»„ï¼Œä»¥æ–¹ä¾¿åé¢çš„è¿ç®—ã€‚å› æ­¤å°†è¯¥æ ·æœ¬è½¬æ¢æˆï¼š
 
x = $\left\lgroup \matrix{R_{1\,1} \cr R_{1\,2} \cr ... \cr R_{2\,1} \cr R_{2\,2} \cr ... \cr G_{1\,1} \cr G_{1\,2} \cr ... \cr B_{1\,1} \cr B_{1\,2} \cr ... } \right \rgroup$ å®ƒåŒ…å«64Ã—64Ã—3=12288ä¸ªå…ƒç´ ï¼Œå†™ä½œn=$n_{x}$=12288ï¼Œè¿™æ˜¯æ ·æœ¬çš„ç»´æ•°ã€‚

å‡è®¾å…±æœ‰mä¸ªæ ·æœ¬ï¼Œæ ·æœ¬ç©ºé—´å¯ä»¥å†™ä½œï¼š

$X=\begin{bmatrix}\mid&\mid&&\mid\\x^{(1)}&x^{(2)}&\cdots&x^{(m)}\\ \mid&\mid&&\mid\end{bmatrix} , Y=[y^{(1)} y^{(2)} ... y^{(m)}] \;$ 

å…¶ä¸­: $x^{(i)}\in \mathbb{R}^{n_{x}}ï¼Œy^{(i)}\in \{0, 1\}; X\in\mathbb{R}^{n_{x}Ã—m}ï¼ŒX.shape=(n_{x}, m);  Y\in \mathbb{R}ï¼Œ Y.shape=(1, m)$

# 2.2 é€»è¾‘å›å½’é—®é¢˜

å¯¹ä¸€å¼ å›¾ç‰‡åˆ¤çŒ«çš„é—®é¢˜æ˜¯ä¸€ä¸ªé€»è¾‘å›å½’é—®é¢˜ï¼Œå³ç»™å®šxï¼Œæ±‚è§£Å·=P(y=1|x)ï¼Œå³y=1çš„æ¦‚ç‡ã€‚

å¯¹äºå›¾ç‰‡$x\in(n_{x}, 1)$ï¼Œå¯ä»¤$Å·=Ïƒ(w^{T}x+b)$ï¼Œ å…¶ä¸­$w\in\mathbb{R}^{n_{x}}, b\in\mathbb{R}$

è¯¥å‡½æ•°å°†å›¾ç‰‡ä¸­çš„åƒç´ ç‚¹æ˜ å°„ä¸ºä»‹äº(0, 1)ä¹‹é—´çš„ä¸€ä¸ªæ•°å­—ï¼Œè¯¥æ•°å­—å°±è¡¨ç¤ºå…¶ä¸­æ˜¯å¦åŒ…å«çŒ«çš„æ¦‚ç‡ï¼Œå‡½æ•°çš„å›¾åƒå¦‚ä¸‹ï¼š
![](0311DeepLearningAI02/sigmoid.png)
å…¶ä¸­$z=w^{T}x+b ï¼Œ\; \; \; Ïƒ(z)=\frac{1}{1+e^{-z}}$

å½“$z->+\infty, \; Ïƒ(z)â‰ˆ\frac{1}{1+0}=1$

å½“$z->-\infty, \; Ïƒ(z)â‰ˆ\frac{1}{1+\infty}=0$

äºæ˜¯æœ¬èŠ‚é¢˜ç›®å°±æ˜¯è¦æ‰¾åˆ°åˆé€‚çš„wå’Œbä½¿å¾—å¯¹äºæ‰€æœ‰æ ·æœ¬xï¼Œè®¡ç®—å‡ºçš„Å·éƒ½èƒ½é€¼è¿‘yã€‚

# 2.3 é€»è¾‘å›å½’çš„æŸå¤±å‡½æ•°å’Œæˆæœ¬å‡½æ•°

å¯¹äºç»™å®šæ ·æœ¬$Å·=Ïƒ(w^{T}x+b) \;, where \, Ïƒ(z)=\frac{1}{1+e^{-z}}$å®šä¹‰æŸå¤±å‡½æ•°ï¼š

$L(Å·, y)=\frac{1}{2}(Å·-y)^{2}$

åªéœ€è¦æ‰¾åˆ°ä»¤æˆæœ¬å‡½æ•°å€¼æœ€å°çš„wå’Œbå³å¯ã€‚ä½†ç”±äºè¯¥å‡½æ•°æ˜¯ä¸ªéå‡¸å‡½æ•°ï¼Œæ‰¾å®ƒçš„å…¨å±€æœ€ä¼˜è§£æ¯”è¾ƒå›°éš¾ï¼Œé€šå¸¸é‡‡ç”¨å˜é€šçš„æ–¹å¼ï¼Œä»¤æŸå¤±å‡½æ•°ï¼š

$L(Å·, y)=-(y\logÅ· + (1-y)\log(1-Å·))$

å½“y=1æ—¶$L(Å·, y)=-\logÅ·$ï¼Œ å¸Œæœ›L(Å·, y)éå¸¸å°ï¼Œè¿™å°±è¦æ±‚$\logÅ·$è¶³å¤Ÿå¤§ï¼Œè¿™è¦æ±‚Å·è¶³å¤Ÿå¤§ï¼Œä½†Å·æ˜¯Ïƒå‡½æ•°ï¼Œæœ€å¤§ä¹Ÿå°±æ— é™æ¥è¿‘1ï¼›

å½“y=0æ—¶$L(Å·, y)=-\log(1-Å·)$ï¼Œ å¸Œæœ›L(Å·, y)éå¸¸å°ï¼Œè¿™å°±è¦æ±‚$\log(1-Å·)$è¶³å¤Ÿå¤§ï¼Œè¿™è¦æ±‚Å·è¶³å¤Ÿå°ï¼Œä½†Å·æ˜¯Ïƒå‡½æ•°ï¼Œæœ€å¤§ä¹Ÿå°±æ— é™æ¥è¿‘0ï¼›

ä»ä¸Šé¢çš„è¶‹åŠ¿åˆ†æä¸Šæ¥çœ‹ï¼Œâ€œÅ·æ— é™æ¥è¿‘yâ€å’Œâ€œL(Å·, y)è¶³å¤Ÿå°â€çš„è¶‹åŠ¿æ˜¯ä¸€è‡´çš„ã€‚

> æˆ‘çš„é—®é¢˜æ˜¯ï¼šåº”è¯¥è®©æŸå¤±å‡½æ•°L(Å·, y)è¶‹è¿‘äº0ï¼Œè€Œä¸æ˜¯æ— é™å°åˆ°è´Ÿæ•°å§ï¼Ÿå› ä¸ºä»ç›´è§‚æ„ä¹‰ä¸Šæ¥çœ‹æŸå¤±å‡½æ•°è¡¨ç¤ºÅ·å’Œyä¹‹é—´çš„å·®è·ï¼Œå¤ªå¤§å’Œå¤ªå°éƒ½ä¸å¯¹å‘€ï¼Ÿ

æŸå¤±å‡½æ•°æ˜¯ä½œä¸ºå•æ ·æœ¬è€Œè¨€çš„ï¼Œå¯¹äºæ•´ä¸ªæ ·æœ¬ç©ºé—´ï¼Œåˆ™è¦è€ƒå¯Ÿæˆæœ¬å‡½æ•°

$J(w, b) = \frac{1}{m}\sum_{i=1}^{m} [y^{(i)}\logÅ·^{(i)} + (1-y^{(i)})\log(1-Å·^{(i)})]$

# 2.4 æ¢¯åº¦ä¸‹é™æ³•

å¯¹äºä¸€ç»´å‡¸å‡½æ•°
![](0311DeepLearningAI02/GradientDescent.png)
$Repeat\{ \\ ã€€w := w - \alpha\frac{dJ_{(w)}}{dw} \\ \}$

å…ˆéšæœºæ‰¾ä¸€ä¸ªç‚¹ï¼Œè®¡ç®—å‡½æ•°åœ¨æ­¤å¤„çš„å¯¼æ•°ï¼Œå†ä¸æ–­é‡å¤è¿ç®—$w := w - \alpha\frac{dJ_{(w)}}{dw}$ç›´åˆ°å‡½æ•°ä¸å‰ä¸€ä¸ªç‚¹çš„å·®å€¼å°äºæŸä¸ªé˜ˆå€¼ã€‚Î±å«åšå­¦ä¹ ç‡ï¼Œæ˜¯æ¯æ¬¡è¿­ä»£çš„æ­¥é•¿ã€‚é€šè¿‡è¿™ç§æ–¹æ³•æ‰¾åˆ°å‡½æ•°çš„æœ€å°å€¼ï¼Œè¿™å°±æ˜¯æ¢¯åº¦ä¸‹é™æ³•ã€‚

å¯¹äºæˆæœ¬å‡½æ•°ï¼Œå®ƒæœ‰å¤šä¸ªå˜é‡ï¼Œä¸ä¸€ç»´å‡½æ•°ä¸åŒä¹‹å¤„åœ¨äºåŸæ¥çš„æ±‚å¯¼è¿ç®—è¦æ”¹æˆæ±‚åå¯¼ï¼ŒåŸç†å’Œä¸€ç»´å‡½æ•°æ˜¯ä¸€æ ·çš„ã€‚å¯¹äºJ(w, b)ï¼š

$Repeat\{ \\ ã€€w := w - \alpha\frac{dJ(w, b)}{dw} \\ ã€€b := b - \alpha\frac{dJ(w, b)}{db} \\ \}$

> å¯¹äºä¸€ç»´å‡½æ•°ï¼Œä¸ºå•¥ä¸è®©Î±å¯¹åº”ä¸€ä¸ªå‡ ä½•æ„ä¹‰ï¼Ÿæˆ‘ç›´è§‚ç†è§£è®¤ä¸ºÎ±æœ¬åº”æ˜¯å¼¦é•¿ï¼Œä½†ä¸å¹¸çš„æ˜¯$\frac{dJ(w)}{dw}$æ˜¯æ–œç‡è€Œä¸æ˜¯cosï¼å› æ­¤æ‰€è°“çš„æ­¥é•¿Î±åªæ˜¯ä¸€ä¸ªæ•°å€¼ï¼Œå…¶ä¹˜æ•°$\frac{dJ(w)}{dw}$ä¹Ÿåªè¡¨æ˜ä¸€ä¸ªå¤§è‡´çš„æ–¹å‘ã€‚

# 2.8 å¯¼æ•°è®¡ç®—ä¹‹è®¡ç®—å›¾

> æœ¬èŠ‚é¦–æ¬¡æåˆ°äº†â€œæ­£å‘ä¼ æ’­â€å’Œâ€œåå‘ä¼ æ’­â€ï¼Œæ­£å‘ä¼ æ’­å°±æ˜¯å°†å„å˜é‡ç»„ç»‡æˆå¤åˆå‡½æ•°ï¼Œåå‘ä¼ æ’­å°±æ˜¯å¯¹å¤åˆå‡½æ•°é€çº§æ±‚å¯¼ã€‚è¿™ä¹ˆç®€å•çš„è¿‡ç¨‹ä¸ºä»€ä¹ˆç§°ä¸ºâ€œæ­£å‘ä¼ æ’­ç®—æ³•â€å’Œâ€œåå‘ä¼ æ’­ç®—æ³•â€å‘¢ï¼Ÿ

# 2.9 é€»è¾‘å›å½’ä¸­çš„æ¢¯åº¦ä¸‹é™æ³•

ç»™å®š

$z = w^{T}x+b  ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€... â‘  \\ Å· = a = Ïƒ(z)=\frac{1}{1+e^{-z}} ã€€ã€€ã€€ã€€ã€€ã€€... â‘¡ \\ L(a, y) = -(y\log(a) + (1-y)\log(1-a)) ã€€... â‘¢$

æ¥ä¸‹é€çº§ç»„ç»‡å¤åˆå‡½æ•°ï¼š
![](0311DeepLearningAI02/img01.png)
å†åˆ©ç”¨è®¡ç®—å›¾æ±‚å¯¼ï¼š
â‘£ $da = \frac{dL(a, y)}{da} = -\frac{y}{a} + \frac{(1-y)}{(1-a)}$

â‘¤ $dz = \frac{dL}{dz} = \frac{dL}{da} \frac{da}{dz}$

 ã€€ã€€$= (-\frac{y}{a} + \frac{(1-y)}{(1-a)}) (-1)(1+e^{-z})^{-2}(-1)e^{-z}$ ã€€ã€€ã€å°†â‘£ä»£å…¥$\frac{dL}{da}$ï¼Œå¹¶å¯¹â‘¡æ±‚å¯¼ã€‘

 ã€€ã€€$= (-\frac{y}{a} + \frac{(1-y)}{(1-a)}) \frac{1}{1+e^{-z}} \frac{e^{-z}}{1+e^{-z}}$

 ã€€ã€€ $=(-\frac{y}{a} + \frac{(1-y)}{(1-a)})a(1-a)$ ã€€ã€€ã€€ã€€ã€€ã€å°†â‘¡ä»£å…¥ã€‘

 ã€€ã€€$=-y(1-a) + a(1-y) \\ =a - y$

â‘¥ $dw_{1} = \frac{dL}{dw_{1}} = \frac{dL}{dz} \frac{dz}{dw_{1}} = dz x_{1} = x_{1} dz$

 ã€€$dw_{2} = x_{2} dz$

 ã€€$db = dz$
  

å°†â‘¥ä»£å…¥æ¢¯åº¦ä¸‹é™æ³•å¾—åˆ°ï¼š

$Repeat\{ \\ w_{1} := w_{1} - Î± Â· dw_{1} \\ w_{2} := w_{2} - Î± Â· dw_{2} \\ b := b - Î± Â· db \\ \}$

# 2.10 æœ‰mä¸ªæ ·æœ¬çš„æ¢¯åº¦ä¸‹é™æ³•

ç»“åˆä¸Šä¸€èŠ‚ç»“è®ºï¼Œå½“æœ‰mä¸ªæ ·æœ¬æ—¶ï¼Œæˆæœ¬å‡½æ•°ï¼š

$J(w, b) = \frac{1}{m} \sum_{i=1}^{m}L(a^{(i)}, y^{(i)})$

å…¶ä¸­$a^{(i)} = Å·^{(i)} = Ïƒ(z^{(i)} = Ïƒ(w^Tx^{(i)} + b)$

äºæ˜¯$\frac{dJ(w,b)}{dw} = \frac{1}{m}\sum_{i=1}^{m}\frac{d}{dw}L(a^{(i)}, y{(i)})$

åº”ç”¨æ¢¯åº¦ä¸‹é™çš„ä¼ªä»£ç è¡¨ä¸ºï¼š

$J=0; dw_{1}=0; dw_{2}=0; db=0; \\ For i=1..m   ã€€ã€€ ã€å¾ªç¯Iã€‘ \\ ã€€z^{(i)}=w^{T}x^{(i)}+b  \\ ã€€a^{(i)} = Ïƒ(z^{(i)}) \\ ã€€J += -[y^{(i)}\log a^{(i)} + (1-y^{(i)})\log(1-a^{(i)})] \\ ã€€dz^{(i)} = a^{(i)} - y^{(i)} ã€€ã€€ã€å°†â‘¤ä»£å…¥ã€‘ã€€ \\ ã€€dw_{1} += {x_{1}}^{(i)}dz^{(i)}  ã€€ ã€å°†â‘¥ä»£å…¥ã€‘ ã€å¾ªç¯IIã€‘ \\ ã€€dw_{2} += {x_{2}}^{(i)}dz^{(i)} \\ ã€€db += dz^{(i)} \\ J=J/m; \; dw_{1}=dw_{1}/m; \; dw_{2}=dw_{2}/m; \; db=db/m; \\ w_{1} := w_{1} - Î±Â·dw_{1} \\ w_{2} := w_{2} - Î±Â·dw_{2} \\ b := b - Î±Â·db$

è¿™åªåº”ç”¨äº†ä¸€è½®æ¢¯åº¦ä¸‹é™ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªå¾ªç¯ï¼šã€å¾ªç¯Iã€‘æ˜¯éå†æ‰€æœ‰æ ·æœ¬ï¼Œã€å¾ªç¯IIã€‘æ˜¯éå†æ¯ä¸ªæ ·æœ¬é‡Œçš„æ‰€æœ‰ç‰¹å¾ã€‚

# 2.11å‘é‡åŒ–

ç†è®ºå·²ç»è®²å®Œäº†ï¼Œå‰©ä¸‹çš„å·¥ä½œå°±æ˜¯å¦‚ä½•é€šè¿‡å‘é‡åŒ–æ¶ˆé™¤å‰ä¸€å°èŠ‚ä¸­çš„ä¸¤ä¸ªå¾ªç¯ï¼Œè®©ä»£ç è·‘å¾—æ›´æœ‰æ•ˆç‡ã€‚
``` python
import numpy as np

a = np.random.rand(100000)
b = np.random.rand(100000)

c = np.dot(a, b)    # â‘ 

for i in range(100000):  # â‘¡
    c += a[i]*b[i]
```
ä»£ç â‘ å’Œâ‘¡åœ¨ç»“æœä¸Šæ˜¯ç­‰ä»·çš„ï¼Œå‰è€…å°±æ˜¯å‘é‡åŒ–çš„å†™æ³•ï¼Œæ›´ç®€æ´ä¸”æ›´æœ‰æ•ˆç‡ã€‚

å¯¹äº$z=w^{T}x+b$ï¼Œå…¶ä¸­$w=\left\lgroup \matrix{w_{1} \cr w_{2} \cr ... \cr w_{n_{x}} }\right \rgroup$ï¼Œ$x=\left\lgroup \matrix{x_{1} \cr x_{2} \cr ... \cr x_{n_{x}} }\right \rgroup$ï¼Œ $w\in\mathbb{R}^n_{x}, \;x\in\mathbb{R}^n_{x}$

æ±‚è§£zéå‘é‡åŒ–çš„å†™æ³•ï¼š
``` python
z=0
for i in range(nx):
    z += w[i] * x[i]
z += b
```
å‘é‡åŒ–çš„å†™æ³•åªéœ€è¦ï¼š
``` python
import numpy as np
z = np.dot(w, x) + b
```

CPUå’ŒGPUéƒ½æœ‰å¹¶è¡ŒåŒ–çš„æŒ‡ä»¤ï¼Œåˆå«SIMDï¼ˆå•æŒ‡ä»¤æµå¤šæ•°æ®æµ single instruments multiple dataï¼‰ï¼Œåœ¨pythonä¸­æœ‰ä½¿ç”¨SIMDçš„å†…ç½®å‡½æ•°ï¼Œå¦‚`np.function`ï¼ŒGPUæ›´æ“…é•¿æ‰§è¡ŒSIMDã€‚

# 2.12 æ›´å¤šå‘é‡åŒ–çš„ä¾‹å­
å°½é‡ä½¿ç”¨npçš„å‘é‡ç”»å‡½æ•°æ¥å–ä»£forå¾ªç¯ï¼Œä¾‹å¦‚ï¼š

$v=\left\lgroup \matrix{v_{1} \cr v_{2} \cr ... \cr v_{n} }\right \rgroup$ï¼Œæ±‚$u=\left\lgroup \matrix{e^{v_{1}} \cr e^{v_{2}} \cr ... \cr e^{v_{n}} }\right \rgroup$

``` python
u = np.zeros((n, 1))
for i in range(n):    # éå‘é‡åŒ–çš„å†™æ³•
    u[i] = math.exp(v[i])
    
u = np.exp(v)      # å‘é‡åŒ–çš„å†™æ³•
```
æ¥ä¸‹æ¥åˆ©ç”¨å‘é‡åŒ–å°†2.10ä¼ªç ä¸­çš„forå¾ªç¯æ¶ˆé™¤æ‰ï¼š

$J=0; \\ dw_{1}=0; dw_{2}=0; ã€€ã€æ›¿æ¢ä¸ºdw = np.zeros((n_x, 1))ã€‘ \\ db=0; \\ For i=1..m \\ ã€€z^{(i)}=w^{T}x^{(i)}+b  ã€€ã€æ›¿æ¢ä¸ºZ=W.T * X + b = np.dot(W.T, X) + bã€‘ \\ ã€€a^{(i)} = Ïƒ(z^{(i)})   ã€€ ã€€ ã€€ã€æ›¿æ¢ä¸ºA = sigmoid(Z)ã€‘ \\ ã€€J += -[y^{(i)}\log a^{(i)} + (1-y^{(i)})\log(1-a^{(i)})] \\ ã€€dz^{(i)} = a^{(i)} - y^{(i)} ã€€ã€æ›¿æ¢ä¸ºdZ = A - Yã€‘ \\ ã€€dw_{1} += {x_{1}}^{(i)}dz^{(i)}  ã€€ ã€æ›¿æ¢ä¸ºdW = (1/m) * X * dZã€‘ \\ ã€€dw_{2} += {x_{2}}^{(i)}dz^{(i)} \\ ã€€db += dz^{(i)}  ã€€   ã€€ ã€€ã€€ ã€€ã€æ›¿æ¢ä¸ºdb = (1/m) * np.sum(dZ)ã€‘ \\ J=J/m; \\ dw_{1}=dw_{1}/m; \; dw_{2}=dw_{2}/m;    ã€€ ã€æ›¿æ¢ä¸ºdW /= mã€‘ \\ db=db/m; \\ w_{1} := w_{1} - Î±Â·dw_{1} \\ w_{2} := w_{2} - Î±Â·dw_{2} \\ b := b - Î±Â·db$

# 2.13 æœ‰mä¸ªæ ·æœ¬çš„å‘é‡åŒ–é€»è¾‘å›å½’

å¯¹äºæœ‰mä¸ªæ ·æœ¬ï¼š

$z^{(1)} = w^{T}x^{(1)} + b \; \; \; z^{(2)} = w^{T}x^{(2)} + b \; \; ... \; z^{(m)} = w^{T}x^{(m)} + b \; \; \;$

$a^{(1)}=Ïƒ(z^{(1)}) \; \; \; \; \; \; \; a^{(2)}=Ïƒ(z^{(2)}) \; \; \; \; \; \; ... \; a^{(m)}=Ïƒ(z^{(m)}) \; \; \;$

å¯ä»¤$X=\begin{bmatrix}\mid&\mid&&\mid\\x^{(1)}&x^{(2)}&\cdots&x^{(m)}\\ \mid&\mid&&\mid\end{bmatrix} \; \in \mathbb{R}^{n_{x}Ã—m}$ 

åˆ™$Z = [Z^{(1)} \; Z^{(2)} \; ... \; Z^{(m)}] = W^{T}Â·X + [b, b, ..., b] $

ä½¿ç”¨å‘é‡åŒ–çš„ä»£ç å†™ä½œ
``` python
Z = np.dot(W.T, X) + b
```
å®æ•°bè¢«è‡ªåŠ¨æ‰©å±•ä¸ºçŸ©é˜µï¼Œè¿™åœ¨pythonä¸­è¢«ç§°ä½œå¹¿æ’­ã€‚

$A = [a^{(1)}, a^{(2)}, ..., a^{(m)}] = Ïƒ(Z)$

# 2.14 å‘é‡åŒ–é€»è¾‘å›å½’æˆæœ¬å‡½æ•°çš„æ¢¯åº¦ä¸‹é™æ³•
ç»§ç»­å‘é‡åŒ–2.12ä¸­çš„ä¼ªç ï¼š

$A = [a^{(1)}, a^{(2)}, ..., a^{(m)}] \; \; \; \\ Y = [y^{(1)}, y^{(2)}, ..., y^{(m)}] \\ Z = W^{T}X + b = np.dot(W.T, X) + b \\ A = Ïƒ(Z) \\ dZ = A - Y \\ dW = \frac{1}{m}XdZ^{T} \\ db = \frac{1}{m} np.sum(dZ) \\ W := W - Î±Â·dW \\ b := b - Î±Â·db$

ä»¥ä¸Šæ˜¯ä¸€æ¬¡æ¢¯åº¦ä¸‹é™çš„è¿­ä»£ï¼Œè‹¥è¦è¿›è¡Œnè½®è¿­ä»£ï¼Œè¿˜æ˜¯éœ€è¦ä¸€ä¸ªnçš„å¾ªç¯ï¼Œè¿™ä¸ªæœ€å¤–å±‚å¾ªç¯æ˜¯æ— æ³•é¿å…çš„ã€‚

# ä½œä¸š

ä½œä¸šé¢˜ç›®ä»¥åŠç›¸å…³çš„æ•°æ®åœ¨ç½‘ä¸Šå¯ä»¥æ‰¾å¾—åˆ°ï¼Œç”±äºæ•°æ®é‡å¤ªå¤§ï¼Œå°±ä¸ä¸Šä¼ äº†ã€‚

## é¢˜ç›®
ç»™å®š209ä¸ªè®­ç»ƒæ ·æœ¬å’Œ50ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ä¸€å¼ å›¾ç‰‡å¹¶æ ‡æ³¨äº†è¯¥å›¾ä¸­æ˜¯å¦åŒ…å«çŒ«ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œç”¨æ¥è¯†åˆ«ç»™å®šçš„å›¾ç‰‡ä¸­æ˜¯å¦åŒ…å«çŒ«ã€‚è®­ç»ƒæ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬æ–‡ä»¶æ ¼å¼ä¸€æ ·ï¼Œéƒ½åŒ…å«ä¸‰ä¸ªdatasetï¼š
```
/list_classes, shape:(2, )
    value:[b'non-cat' b'cat']ã€€ã€€ã€€# æ ‡æ³¨è¯å…¸ï¼Œè¡¨ç¤ºæ²¡çŒ«å’Œæœ‰çŒ«çš„æ–‡å­—è¡¨è¿°
 
/train_set_x, shape:(209, 64, 64, 3)   # å…±209å¼ å›¾ç‰‡ï¼Œæ¯å¼ å›¾ç‰‡æ˜¯64 * 64 * 3
    value:[[[[ 17  31  56]        # å›¾ç‰‡æ•°æ®
    [ 22  33  59]
    [ 25  35  62]
    ...,
    [  1  28  57]
    [  1  26  56]
    [  1  22  51]]
    ...
    
/train_set_y, shape:(209,)        # å…±209ä¸ªæ ‡æ³¨
    value:[0 0 1 ... 0 0 0]
```
## ä¸»å¹²é€»è¾‘
ä¸»å¹²ä»£ç å¦‚ä¸‹ï¼š
``` python
# è¿”å›è®­ç»ƒæ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬çš„æ•°æ®ã€æ ‡æ³¨ï¼Œclassesæ˜¯æ ‡æ³¨å¯¹åº”çš„å«ä¹‰
train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = self.load_dataset()

m_train = train_set_x_orig.shape[0]     # è®­ç»ƒæ ·æœ¬çš„ä¸ªæ•°ï¼š209
m_test = test_set_x_orig.shape[0]       # æµ‹è¯•æ ·æœ¬çš„ä¸ªæ•°ï¼š50
num_px = train_set_x_orig.shape[1]      # å›¾ç‰‡çš„å®½ã€é«˜åƒç´ æ•°ï¼š64

# å°†è®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬æ‰å¹³åŒ–ï¼Œå¯¹äºæ¯ä¸€å¼ å›¾ï¼Œå°† (64, 64, 3) çš„å›¾ç‰‡è½¬æˆ(64*64*3, 1)
# å¯¹äºæ•´ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œå°†(209, 64, 64, 3)è½¬æˆ(209, -1).Tï¼Œæ³¨æ„æœ‰ä¸ªè½¬ç½®ï¼Œè½¬ç½®åæ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªæ ·æœ¬ï¼Œ
# æŸåˆ—çš„æ¯ä¸€è¡Œæ˜¯å›¾ç‰‡çš„ä¸€ä¸ªç‰¹å¾ã€‚è®­ç»ƒé›†å…±209è¡Œï¼ˆä¸ªæ ·æœ¬ï¼‰ï¼Œ12288ä¸ªç‰¹å¾ã€‚å‚è§ç¬”è®°2.1ã€‚
train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T
test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T

# æ ‡å‡†åŒ–æ•°æ®ï¼Œè®©æ¯ä¸ªå…ƒç´ âˆˆ[0, 1]
train_set_x = train_set_x_flatten / 255.
test_set_x = test_set_x_flatten / 255.

# è®­ç»ƒå‡ºæ¨¡å‹ ğŸ
d = self.model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)

# éªŒè¯æ¨¡å‹
fname = os.path.join(self.imagesDir, 'my_image2.jpg')
image = np.array(ndimage.imread(fname, flatten=False))
my_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((1, num_px*num_px*3)).T
my_predicted_image = self.predict(d['w'], d['b'], my_image)
logging.info(my_predicted_image)
```
## è®­ç»ƒæ¨¡å‹
ä¸»å¹²é€»è¾‘éå¸¸ç®€å•ï¼Œæ— éœ€è¿‡å¤šè§£é‡Šï¼Œæ·±å…¥æ¨¡å‹è®­ç»ƒéƒ¨åˆ†ï¼š
``` python
def model(self, X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):
    w, b = self.initialize_with_zeros(X_train.shape[0]) # wå…ƒç´ ä¸ªæ•°ç­‰äºç‰¹å¾æ•°ï¼Œbæ˜¯ä¸€ä¸ªå®æ•°ï¼Œå°†ä»–ä»¬åˆå§‹åŒ–ä¸º0

    # å­¦ä¹ ç‡ä¸ºlearning_rateï¼Œç»è¿‡num_iterationsè½®è¿­ä»£ï¼Œè·å¾—æ¨¡å‹å‚æ•° ğŸ
    parameters, grads, costs = self.optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost=True)

    w = parameters["w"]
    b = parameters["b"]

    # éªŒè¯æ¨¡å‹åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡
    Y_prediction_test = self.predict(w, b, X_test)
    Y_prediction_train = self.predict(w, b, X_train)
    print("train accuracy: {} %".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))
    print("test accuracy: {} %".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))

    # è¿™æ˜¯æ„æˆæ¨¡å‹çš„å…¨éƒ¨å…ƒç´ ï¼Œå¯¹æœªæ¥æœ‰ç”¨çš„å°±æ˜¯wå’Œb
    d = {"costs": costs,
         "Y_prediction_test": Y_prediction_test, 
         "Y_prediction_train" : Y_prediction_train, 
         "w" : w, 
         "b" : b,
         "learning_rate" : learning_rate,
         "num_iterations": num_iterations}

    return d
```
### å¤šè½®è¿­ä»£
æ‰€è°“â€œæ¨¡å‹â€æ ¸å¿ƒå°±æ˜¯ç»è¿‡è‹¥å¹²è½®æ¢¯åº¦ä¸‹é™æ³•çš„è¿­ä»£ï¼Œå¾—åˆ°ä»¤æˆæœ¬å‡½æ•°æœ€å°çš„wå’Œbï¼Œè®­ç»ƒçš„æ ¸å¿ƒé€»è¾‘åœ¨å‡½æ•°`optimize(...)`ä¸­ï¼š
``` python
def optimize(self, w, b, X, Y, num_iterations, learning_rate, print_cost = False):
    costs = []

    for i in range(num_iterations):
        grads, cost = self.propagate(w, b, X, Y) # ä¸€æ¬¡æ¢¯åº¦ä¸‹é™ğŸ

        dw = grads["dw"]
        db = grads["db"]

        w = w - learning_rate * dw
        b = b - learning_rate * db

        # Record the costs
        if i % 100 == 0:
            costs.append(cost)

        ...

    params = {"w": w, "b": b}

    grads = {"dw": dw, "db": db}

    return params, grads, costs
```
### æ¢¯åº¦ä¸‹é™
`propagate(...)`ä¸­æ˜¯æ¢¯åº¦ä¸‹é™çš„æ ¸å¿ƒé€»è¾‘ï¼Œå¯¹åº”ç¬”è®°çš„2.14ï¼š
``` python
def propagate(self, w, b, X, Y):
    m = X.shape[1]

    A = self.sigmoid(np.dot(w.T,X) + b)            # compute activation
    cost = -(np.sum(np.dot(Y,np.log(A).T)+np.dot((1-Y),np.log(1-A).T)))/m      # compute cost

    dw = (np.dot(X,(A-Y).T))/m
    db = (np.sum(A-Y))/m

    ...
    cost = np.squeeze(cost)

    grads = {"dw": dw, "db": db}

    return grads, cost
```

è¿‡ç¨‹è¿˜æ˜¯éå¸¸æ¸…æ™°çš„ï¼Œæ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œå°†è®­ç»ƒæ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬ä»£å…¥æ¨¡å‹ï¼Œå¯ä»¥å¾—åˆ°è®­ç»ƒæ ·æœ¬çš„ç²¾åº¦æ˜¯99%ï¼Œæµ‹è¯•æ ·æœ¬çš„ç²¾åº¦æ˜¯70%ï¼š
```
train accuracy: 99.04306220095694 %
test accuracy: 70.0 %
```
éšä¾¿æ‰¾å¼ å›¾ï¼Œå¸¦å…¥`predict(...)`å‡½æ•°ï¼Œå³å¯éªŒè¯æœ‰æ•ˆæ€§ã€‚

# æ€è€ƒ
ç¡®å®å’Œä¼ ç»Ÿçš„ç¼–ç¨‹æ€è·¯å®Œå…¨ä¸åŒï¼šä¼ ç»Ÿçš„ç¼–ç¨‹æ€è·¯ä¸­å¯¹/é”™æ˜¯ä¸ªç¡®å®šçš„å€¼ï¼Œæ­£å¦‚if/elseæˆ–true/falseï¼Œéæ­¤å³å½¼çš„ã€‚å½“ç»“æœå’Œé¢„æœŸå‘ç”Ÿä¸ä¸€è‡´ï¼Œé‚£å«bugï¼Œé¡ºç€ä»£ç å¾€é‡ŒæŸ¥ï¼Œä¸€å®šèƒ½æŸ¥åˆ°ä¸ä¸€è‡´çš„åŸå› ã€‚

è€Œæ·±åº¦å­¦ä¹ ä¼¼ä¹æ›´é è¿‘çœŸå®ä¸–ç•Œï¼Œå› ä¸ºçœŸå®ä¸–ç•Œä¸­å¾ˆå¤šåˆ¤æ–­ä¸æ˜¯éé»‘å³ç™½ï¼Œè€Œæ˜¯æ¦‚ç‡çš„ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸–ç•Œçš„æœ¬è´¨ã€‚ä½†è¿™ç»™é—®é¢˜çš„è§£å†³å¸¦æ¥éº»çƒ¦â€”â€”å½“ç»“æœå’Œé¢„æœŸä¸ä¸€è‡´æ—¶ï¼Œä½ æ²¡æœ‰å¯é¡ºè—¤æ‘¸ç“œçš„é€»è¾‘ç‚¹æ¥è¡¨æ˜åˆ°åº•å“ªé‡Œå‡ºäº†é—®é¢˜ã€‚æœ€å¤šåªèƒ½ç¡®è®¤â€œæ¢¯åº¦ä¸‹é™â€çš„ç®—æ³•æ˜¯ä¸æ˜¯æ­£ç¡®ï¼Œæ¨¡å‹äº§ç”Ÿçš„æ˜¯ä¸€æ‰¹ç¥ç»å…ƒï¼Œé’ˆå¯¹å…·ä½“çš„ä¸€å¼ å›¾ç‰‡ï¼Œæ— æ³•äººè‚‰åˆ¤æ–­æŸä¸ªç¥ç»å…ƒçš„æƒé‡æ˜¯å¦æ­£ç¡®ã€‚

ä½œä¸šé‡Œimages/ä¸­çš„å›¾ç‰‡ï¼Œæ¨¡å‹éƒ½èƒ½åˆ¤æ–­æ­£ç¡®ï¼Œä½†æˆ‘ä»ç½‘ä¸Šéšä¾¿æ‰¾å‡ å¼ çŒ«å›¾æ‰”ç»™æ¨¡å‹ï¼Œç»“æœæ˜¯é”™è¯¯çš„ã€‚æˆ‘ä¸çŸ¥é“è¯¥å¦‚ä½•æ”¹è¿›æ‰èƒ½è®©æ–°å›¾è¯†åˆ«æ­£ç¡®ã€‚ç›´è§‚çš„æƒ³æ³•å¯èƒ½æ˜¯å–‚ç»™æ¨¡å‹æ›´å¤šçš„è®­ç»ƒæ ·æœ¬ï¼Œå¯æ˜¯å¦‚ä½•åšå‡ºä¸€ä¸ªé‡åŒ–çš„é¢„æµ‹å‘¢ï¼Ÿéœ€è¦å–‚å¤šå°‘ï¼Ÿèƒ½è¾¾åˆ°ä»€ä¹ˆæ ·çš„æ°´å¹³ï¼Ÿä¸åŒçš„äººç±»å¤§è„‘å¯¹äºæ–°äº‹ç‰©çš„å­¦ä¹ æ•ˆç‡ä¹Ÿæ˜¯ä¸ä¸€æ ·çš„ï¼Œå¯¹äºåŒä¸€æ‰¹æ ·æœ¬ï¼Œæœ‰æ²¡æœ‰å¯èƒ½æ”¹è¿›æ¨¡å‹ï¼Œä»¤å…¶æ•ˆæœå¾—åˆ°æå‡å‘¢ï¼Ÿæ€ä¹ˆæ”¹è¿›ï¼Ÿ

æˆ‘ç›¸ä¿¡è¿™äº›é—®é¢˜åœ¨æœªæ¥çš„è¯¾ç¨‹ä¸­ä¼šæœ‰è§£ç­”ï¼Œç»§ç»­å­¦ä¹ å§ï¼

------
æœ¬æ–‡ä»£ç å‚è§[https://github.com/palanceli/MachineLearningSample/blob/master/DeepLearningAIHomeWorks/mywork.py](https://github.com/palanceli/MachineLearningSample/blob/master/DeepLearningAIHomeWorks/mywork.py)çš„`class Coding1_1`éƒ¨åˆ†ã€‚